{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hkhc10wNrGt",
        "outputId": "8e5acd7f-39d1-440b-ac79-53e85b12300e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoModel, BertTokenizerFast, TFBertModel, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Use GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")   # Use CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OIi5b5NwTDh"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/archive/train.csv',encoding='iso-8859-1')[['text', 'sentiment']];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LmS6zUZGwRs0",
        "outputId": "353c326f-db5e-4c8c-94d1-fdbf74f99d9f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 27481,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27480,\n        \"samples\": [\n          \" Enjoy! Family trumps everything\",\n          \" --of them kinda turns me off of it all.  And then I buy more of them and dig a deeper hole, etc. ;;\",\n          \"Clive it`s my birthday pat me  http://apps.facebook.com/dogbook/profile/view/6386106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9b196dd8-c639-4e0f-8f9c-c66a54fb91ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b196dd8-c639-4e0f-8f9c-c66a54fb91ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b196dd8-c639-4e0f-8f9c-c66a54fb91ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b196dd8-c639-4e0f-8f9c-c66a54fb91ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f35308c-0add-4151-93c9-18b5bc41dc52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f35308c-0add-4151-93c9-18b5bc41dc52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f35308c-0add-4151-93c9-18b5bc41dc52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0                I`d have responded, if I were going   neutral\n",
              "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
              "2                          my boss is bullying me...  negative\n",
              "3                     what interview! leave me alone  negative\n",
              "4   Sons of ****, why couldn`t they put them on t...  negative"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWJPgw0qMAT4"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkuHxWh2MEqk"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocessing(text):\n",
        "  regex = r'[^\\w\\s]|[\\U0001f600-\\U0001f64f\\U0001f300-\\U0001f5ff\\U0001f680-\\U0001f6ff\\U0001f1e0-\\U0001f1ff]'\n",
        "  text=re.sub(regex,\" \",text)\n",
        "  text=re.sub(\"\\.|\\,|\\/|\\-\",\" \",text)\n",
        "  text=re.sub(\"\\s*\\s\",\" \",text)\n",
        "  return text\n",
        "for i in range(len(train_df)):\n",
        "  train_df.loc[i,\"text\"]=preprocessing(str(train_df.loc[i,\"text\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "676DPU1BOPdp",
        "outputId": "eab457e1-23c7-4ce8-9670-a7c438e90c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train_data  sentiment\n",
            "0    11118\n",
            "1     8582\n",
            "2     7781\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_df.dropna(subset=['text'], inplace=True)\n",
        "train_df[\"sentiment\"]=train_df[\"sentiment\"].replace({\"neutral\":0,\"positive\":1,\"negative\":2})\n",
        "\n",
        "# Class distribution for the train set\n",
        "print(\"train_df \", train_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqC_peuHuuMS"
      },
      "outputs": [],
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(train_df['text'], train_df['sentiment'],\n",
        "                                                                    random_state=2024,\n",
        "                                                                    test_size=0.15,\n",
        "                                                                    stratify=train_df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKwbpeN_PMiu"
      },
      "outputs": [],
      "source": [
        "# Max length of text in train texts\n",
        "max_seq_train_len = max([len(i.split()) for i in train_text])\n",
        "max_seq_val_len = max([len(i.split()) for i in val_text])\n",
        "max_seq_len = max(max_seq_train_len, max_seq_val_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk5S7DWaP2t6",
        "outputId": "9ef6caf1-075c-4454-841e-0de2b54345b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "outputs": [],
      "source": [
        "# for train set\n",
        "train_tensorData = TensorDataset(torch.tensor(tokens_train['input_ids']),\n",
        "                                 torch.tensor(tokens_train['attention_mask']),\n",
        "                                 torch.tensor(train_labels.tolist()))\n",
        "# for validation set\n",
        "val_tensorData = TensorDataset(torch.tensor(tokens_val['input_ids']),\n",
        "                               torch.tensor(tokens_val['attention_mask']),\n",
        "                               torch.tensor(val_labels.tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_tensorData)\n",
        "val_sampler = SequentialSampler(val_tensorData)\n",
        "# dataLoader for train set and validation set\n",
        "train_dfloader = DataLoader(train_tensorData, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_tensorData, sampler=val_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LClKJMG6EM-G",
        "outputId": "2b89ea4f-beba-41cd-910b-7562571c4385"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--3 for pos/neu/neg classification.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model = model.to(device) # push the model to GPU\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taXS0IilRn9J",
        "outputId": "be5dba4c-8c4b-4657-e77f-e5202f2ab9de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 1e-5) #Optimizer\n",
        "class_wts = compute_class_weight(class_weight = \"balanced\", #Class weights\n",
        "                                 classes= np.unique(train_labels), y= train_labels)\n",
        "weights= torch.tensor(class_wts,dtype=torch.float) # convert class weights to tensor\n",
        "weights = weights.to(device) # push to GPU\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) # loss function\n",
        "epochs = 10 #Number of training epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    total_preds=[]\n",
        "    for step,batch in enumerate(train_dfloader): # iterate over batches\n",
        "      if step % 100 == 0 and not step == 0: # progress update after every 50 batches.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dfloader)))\n",
        "      batch = [r.to(device) for r in batch]\n",
        "      sent_id, mask, labels = batch # pull the inputs from our dataloader\n",
        "      model.zero_grad()   # clear previously calculated gradients\n",
        "      output = model(sent_id,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=mask,\n",
        "                      labels=labels)\n",
        "      loss, logits = output.loss, output.logits\n",
        "      total_loss += loss.item()\n",
        "      preds = logits\n",
        "      loss.backward() # backward pass to calculate the gradients\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step() # update parameters\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "    avg_loss = total_loss / len(train_dfloader)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsjibpBGS9Ur"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = [] # empty list to save the model predictions\n",
        "  for step,batch in enumerate(val_dataloader): # iterate over batches\n",
        "    if step % 100 == 0 and not step == 0: # Progress update every 50 batches.\n",
        "      print('Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "    batch = [t.to(device) for t in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    with torch.no_grad():\n",
        "      output = model(sent_id,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=mask,\n",
        "                      labels=labels)\n",
        "      loss, logits = output.loss, output.logits\n",
        "      preds = logits\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1USGTntS3TS",
        "outputId": "8173ddb9-1172-4eba-8ba9-abc979bb3520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.658\n",
            "Validation Loss: 0.529\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.481\n",
            "Validation Loss: 0.514\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.394\n",
            "Validation Loss: 0.585\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.313\n",
            "Validation Loss: 0.610\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.232\n",
            "Validation Loss: 0.682\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.178\n",
            "Validation Loss: 0.792\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.138\n",
            "Validation Loss: 0.924\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.113\n",
            "Validation Loss: 1.062\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.092\n",
            "Validation Loss: 1.201\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch   100  of    730.\n",
            "  Batch   200  of    730.\n",
            "  Batch   300  of    730.\n",
            "  Batch   400  of    730.\n",
            "  Batch   500  of    730.\n",
            "  Batch   600  of    730.\n",
            "  Batch   700  of    730.\n",
            "Batch   100  of    129.\n",
            "\n",
            "Training Loss: 0.078\n",
            "Validation Loss: 1.308\n"
          ]
        }
      ],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss, _ = train() #train model\n",
        "    valid_loss, _ = evaluate()  #evaluate model\n",
        "    if valid_loss < best_valid_loss: #save the best model\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deQ0vWxhUx9s",
        "outputId": "ae99b616-b003-4cf8-9216-d5cb377c3f6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZl0SZmFTRQA",
        "outputId": "1f774261-90bd-4107-ae6a-0b7644d36d07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/archive/test.csv',encoding='iso-8859-1')[['text', 'sentiment']];\n",
        "for i in range(len(test_df)):\n",
        "  test_df.loc[i,\"text\"]=preprocessing(str(test_df.loc[i,\"text\"]))\n",
        "test_df.dropna(subset=['text'], inplace=True)\n",
        "test_df[\"sentiment\"]=test_df[\"sentiment\"].replace({\"neutral\":0,\"positive\":1,\"negative\":2})\n",
        "test_text = test_df['text']\n",
        "test_labels = test_df['sentiment'].fillna(0).astype(np.int64)\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist(), dtype=torch.float32)\n",
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  op = model(test_seq.to(device), token_type_ids=None, attention_mask=test_mask.to(device), labels=test_y.to(device).long())\n",
        "  loss, logits = op.loss, op.logits\n",
        "  preds = logits\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms1ObHZxTYSI",
        "outputId": "bfc29351-e4d0-44e1-e351-f0f3562fe1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.89      0.87      2711\n",
            "    negative       0.86      0.80      0.83      1103\n",
            "     neutral       0.80      0.76      0.78      1001\n",
            "\n",
            "    accuracy                           0.84      4815\n",
            "   macro avg       0.84      0.82      0.83      4815\n",
            "weighted avg       0.84      0.84      0.84      4815\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model's performance\n",
        "target_names = ['positive', 'negative', 'neutral']\n",
        "print(classification_report(test_y, preds, target_names=target_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}