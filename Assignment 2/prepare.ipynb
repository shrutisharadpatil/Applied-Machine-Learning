{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define project paths\n",
        "project_path = \"/content/drive/MyDrive/dvc_project\"\n",
        "data_path = os.path.join(project_path, \"data\")\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "# Download the SMS Spam Collection dataset\n",
        "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "dataset_path = os.path.join(data_path, \"smsspamcollection.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")\n",
        "\n",
        "# Extract dataset\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_path)\n",
        "\n",
        "# Convert dataset to CSV format\n",
        "txt_file_path = os.path.join(data_path, \"SMSSpamCollection\")\n",
        "raw_data_path = os.path.join(data_path, \"raw_data.csv\")\n",
        "\n",
        "if os.path.exists(txt_file_path):\n",
        "    print(\"Converting to CSV format...\")\n",
        "    df = pd.read_csv(txt_file_path, sep='\\t', names=[\"label\", \"text\"], encoding='latin-1')\n",
        "\n",
        "    # Convert labels to binary (spam = 1, ham = 0)\n",
        "    df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "    # Save as CSV\n",
        "    df.to_csv(raw_data_path, index=False)\n",
        "    print(f\"Dataset saved as: {raw_data_path}\")\n",
        "else:\n",
        "    print(\"SMSSpamCollection file not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6KEjyQcPgGP",
        "outputId": "15f2ad7e-9cf8-4a3c-b541-f74815d6be19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading dataset...\n",
            "Download complete.\n",
            "Converting to CSV format...\n",
            "Dataset saved as: /content/drive/MyDrive/dvc_project/data/raw_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(raw_data_path)\n",
        "\n",
        "# Train-validation-test split\n",
        "train, temp = train_test_split(df, test_size=0.4, random_state=42)\n",
        "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Save data splits\n",
        "train.to_csv(os.path.join(data_path, \"train.csv\"), index=False)\n",
        "valid.to_csv(os.path.join(data_path, \"validation.csv\"), index=False)\n",
        "test.to_csv(os.path.join(data_path, \"test.csv\"), index=False)\n",
        "\n",
        "print(\"Data split and saved.\")\n",
        "\n",
        "# Track with DVC\n",
        "!pip install dvc[gdrive] -q\n",
        "%cd /content/drive/MyDrive/dvc_project\n",
        "!dvc init\n",
        "!dvc add data/raw_data.csv data/train.csv data/validation.csv data/test.csv\n",
        "!git add data/*.dvc .gitignore\n",
        "!git commit -m \"Tracked dataset versions with DVC\"\n",
        "!dvc push\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRghn35HPnXY",
        "outputId": "54f8342b-c832-4fc9-e654-85ba3450deb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split and saved.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.2/77.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.0/426.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.7/457.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/drive/MyDrive/dvc_project\n",
            "\u001b[31mERROR\u001b[39m: failed to initiate DVC - /content/drive/MyDrive/dvc_project is not tracked by any supported SCM tool (e.g. Git). Use `--no-scm` if you don't want to use any SCM or `--subdir` if initializing inside a subdirectory of a parent SCM repository.\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/4 [00:00<?, ?file/s{'info': ' data/raw_data.csv |'}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "100% 1/1 [00:02<00:00,  2.85s/files{'info': ''}]\u001b[A\n",
            "                                                \u001b[A\n",
            "Adding data/raw_data.csv to cache:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
            "Adding data/raw_data.csv to cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
            "                                                                          \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...:  25% 1/4 [00:03<00:10,  3.62s/file{'info': ' data/train.csv |'}]   \n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "Adding data/train.csv to cache:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
            "Adding data/train.csv to cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
            "                                                                       \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...:  50% 2/4 [00:03<00:03,  1.62s/file{'info': ' data/validation.csv |'}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "Adding data/validation.csv to cache:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
            "Adding data/validation.csv to cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
            "                                                                            \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...:  75% 3/4 [00:04<00:00,  1.02file/s{'info': ' data/test.csv |'}]      \n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "Adding data/test.csv to cache:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
            "Adding data/test.csv to cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 4/4 [00:04<00:00,  1.07s/file{'info': ''}]                \n",
            "\u001b[0mfatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "\u001b[31mERROR\u001b[39m: configuration error - To use service account, set `gdrive_service_account_json_file_path`, and optionally `gdrive_service_account_user_email` in DVC config.\n",
            "\u001b[31mERROR\u001b[39m: To use service account, set `gdrive_service_account_json_file_path`, and optionally `gdrive_service_account_user_email` in DVC config.\n",
            "Learn more about configuration settings at <\u001b[36mhttps://man.dvc.org/remote/modify\u001b[39m>.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_files = os.listdir(\"/content/drive/MyDrive/dvc_project/data\")\n",
        "print(\"Files in data folder:\", data_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL2A01ZGPyTl",
        "outputId": "90dc5cfc-c178-4004-f8ed-177fbcc00c38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in data folder: ['raw_data.csv.dvc', 'raw_data.csv', 'smsspamcollection.zip', 'SMSSpamCollection', 'readme', 'train.csv', 'validation.csv', 'test.csv', 'train.csv.dvc', 'validation.csv.dvc', 'test.csv.dvc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmRWPcewQH2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}