{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJiYPfidQTnJ",
        "outputId": "cc69bb5c-e0ce-4506-9dc4-17251a5add79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.7/648.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install MLflow\n",
        "!pip install mlflow -q\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import average_precision_score\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the dataset\n",
        "data_path = \"/content/drive/MyDrive/dvc_project/data\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSwmGruRNbe",
        "outputId": "6e56bb9f-7ac4-44e4-929f-ee657f9d696f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading data...\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
        "valid = pd.read_csv(os.path.join(data_path, \"validation.csv\"))\n",
        "\n",
        "# Separate features and target\n",
        "X_train_raw, y_train = train[\"text\"], train[\"label\"]\n",
        "X_valid_raw, y_valid = valid[\"text\"], valid[\"label\"]\n",
        "\n",
        "# Convert text into numerical vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train_raw)\n",
        "X_valid = vectorizer.transform(X_valid_raw)\n",
        "\n",
        "print(\"Text data successfully vectorized!\")\n",
        "\n",
        "print(\"Data loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olexolK_Q3vN",
        "outputId": "53b92f74-0ddc-4896-fe2b-6c13d237a0bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Text data successfully vectorized!\n",
            "Data loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up an experiment in MLflow\n",
        "mlflow.set_experiment(\"Spam_Classification\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU38EsoqRVPb",
        "outputId": "4cffc44e-43d1-4787-fb40-5f7b024e39dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///content/mlruns/595921464032175323', creation_time=1741160809907, experiment_id='595921464032175323', last_update_time=1741160809907, lifecycle_stage='active', name='Spam_Classification', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_log_model(model, model_name):\n",
        "    \"\"\"\n",
        "    Trains a model, logs it to MLflow, and prints AUCPR score.\n",
        "    \"\"\"\n",
        "    with mlflow.start_run():\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities\n",
        "        y_pred = model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "        # Compute AUCPR score\n",
        "        aucpr = average_precision_score(y_valid, y_pred)\n",
        "\n",
        "        # Log AUCPR metric\n",
        "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
        "\n",
        "        # Log model\n",
        "        mlflow.sklearn.log_model(model, model_name)\n",
        "\n",
        "        print(f\"{model_name} AUCPR: {aucpr}\")\n"
      ],
      "metadata": {
        "id": "XTMB7vpVRYL3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
        "    \"SVM\": SVC(probability=True)\n",
        "}\n",
        "\n",
        "# Train and log each model\n",
        "for name, model in models.items():\n",
        "    train_and_log_model(model, name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0zKxDUzRabH",
        "outputId": "eef7fd76-45f2-435e-f3ca-afc075ac2d50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/05 07:48:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest AUCPR: 0.9837029179613737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/05 07:49:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression AUCPR: 0.972349844151224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/05 07:49:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM AUCPR: 0.9807715057456959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DgleN7JR9YR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}